<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!-- Put site-specific property overrides in this file. -->
<configuration supports_final="true" xmlns:xi="http://www.w3.org/2001/XInclude">
  <!-- i/o properties -->
  <property>
    <name>io.file.buffer.size</name>
    <value>131072</value>
    <description>The size of buffer for use in sequence files.
  The size of this buffer should probably be a multiple of hardware
  page size (4096 on Intel x86), and it determines how much data is
  buffered during read and write operations.</description>
  </property>
  <property>
    <name>io.serializations</name>
    <value>org.apache.hadoop.io.serializer.WritableSerialization</value>
  </property>
  <property>
    <name>io.compression.codecs</name>
    <value>org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.SnappyCodec</value>
    <description>A list of the compression codec classes that can be used
                 for compression/decompression.</description>
  </property>
  <!-- file system properties -->
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://localhost:8020</value>
    <description>The name of the default file system.  Either the
  literal string "local" or a host:port for NDFS.</description>
    <final>true</final>
  </property>
  <property>
    <name>fs.trash.interval</name>
    <value>360</value>
    <description>Number of minutes after which the checkpoint
      gets deleted.  If zero, the trash feature is disabled.
    </description>
  </property>
  <property>
    <name>fs.trash.checkpoint.interval</name>
    <value>0</value>
    <description>Number of minutes between trash checkpoints.
      Should be smaller or equal to fs.trash.interval. If zero,
      the value is set to the value of fs.trash.interval.
    </description>
  </property>
  <property>
    <name>fs.permissions.umask-mode</name>
    <value>022</value>
    <description>The umask used when creating files and directories.
      Can be in octal or in symbolic. Examples are: "022" (octal for
      u=rwx,g=r-x,o=r-x in symbolic), or "u=rwx,g=rwx,o=" (symbolic
      for 007 in octal).</description>
  </property>
  <property>
    <name>ipc.client.idlethreshold</name>
    <value>8000</value>
    <description>Defines the threshold number of connections after which
               connections will be inspected for idleness.
    </description>
  </property>
  <property>
    <name>ipc.client.connection.maxidletime</name>
    <value>30000</value>
    <description>The maximum time after which a client will bring down the
               connection to the server.
    </description>
  </property>
  <property>
    <name>ipc.client.connect.max.retries</name>
    <value>50</value>
    <description>Defines the maximum number of retries for IPC connections.</description>
  </property>
  <!-- Web Interface Configuration -->
  <property>
    <name>hadoop.http.staticuser.user</name>
    <value>gopher</value>
    <description>
      The user name to filter as, on static web filters
      while rendering content. An example use is the HDFS
      web UI (user to be used for browsing files).
    </description>
  </property>
  <property>
    <name>webinterface.private.actions</name>
    <value>false</value>
    <description> If set to true, the web interfaces of RM and NN may contain
                actions, such as kill job, delete file, etc., that should
                not be exposed to public. Enable this option if the interfaces
                are only reachable by those who have the right authorization.
    </description>
  </property>
  <property>
    <name>hadoop.security.authentication</name>
    <value>simple</value>
    <description>
      Set the authentication for the cluster. Valid values are: simple or
      kerberos.
    </description>
  </property>
  <property>
    <name>hadoop.security.authorization</name>
    <value>false</value>
    <description>
     Enable authorization for different protocols.
  </description>
  </property>
  <property>
    <name>hadoop.proxyuser.hadoop.groups</name>
    <value>HadoopUsers</value>
    <description>
     Proxy group for Hadoop.
  </description>
  </property>
  <property>
    <name>hadoop.ssl.enabled</name>
    <value>false</value>
  </property>
  <property>
    <name>hadoop.ssl.require.client.cert</name>
    <value>false</value>
  </property>
  <property>
    <name>hadoop.ssl.hostname.verifier</name>
    <value>DEFAULT</value>
  </property>
  <property>
    <name>hadoop.ssl.keystores.factory.class</name>
    <value>org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory</value>
  </property>
  <property>
    <name>hadoop.ssl.server.conf</name>
    <value>ssl-server.xml</value>
  </property>
  <property>
    <name>hadoop.ssl.client.conf</name>
    <value>ssl-client.xml</value>
  </property>
  <property>
    <name>hadoop.rpc.protection</name>
    <value>authentication</value>
  </property>
  <property>
    <name>hadoop.tmp.dir</name>
    <value>c:\hdp\temp\hadoop</value>
  </property>

  <property>
    <name>hadoop.proxyuser.hadoop.hosts</name>
    <value>192.168.145.128</value>
  </property>

  <property>
    <name>hadoop.security.auth_to_local</name>
    <value>
        RULE:[2:$1@$0]([rn]m@.*)s/.*/yarn/
        RULE:[2:$1@$0](jhs@.*)s/.*/mapred/
        RULE:[2:$1@$0]([nd]n@.*)s/.*/hdfs/
        RULE:[2:$1@$0](hm@.*)s/.*/hbase/
        RULE:[2:$1@$0](rs@.*)s/.*/hbase/
        DEFAULT
    </value>
<description>The mapping from kerberos principal names to local OS mapreduce.job.user.names.
  So the default rule is just "DEFAULT" which takes all principals in your default domain to their first component.
  "omalley@APACHE.ORG" and "omalley/admin@APACHE.ORG" to "omalley", if your default domain is APACHE.ORG.
The translations rules have 3 sections:
      base     filter    substitution
The base consists of a number that represents the number of components in the principal name excluding the realm and the pattern for building the name from the sections of the principal name. The base uses $0 to mean the realm, $1 to mean the first component and $2 to mean the second component.

[1:$1@$0] translates "omalley@APACHE.ORG" to "omalley@APACHE.ORG"
[2:$1] translates "omalley/admin@APACHE.ORG" to "omalley"
[2:$1%$2] translates "omalley/admin@APACHE.ORG" to "omalley%admin"

The filter is a regex in parens that must the generated string for the rule to apply.

"(.*%admin)" will take any string that ends in "%admin"
"(.*@ACME.COM)" will take any string that ends in "@ACME.COM"

Finally, the substitution is a sed rule to translate a regex into a fixed string.

"s/@ACME\.COM//" removes the first instance of "@ACME.COM".
"s/@[A-Z]*\.COM//" removes the first instance of "@" followed by a name followed by ".COM".
"s/X/Y/g" replaces all of the "X" in the name with "Y"

So, if your default realm was APACHE.ORG, but you also wanted to take all principals from ACME.COM that had a single component "joe@ACME.COM", you'd do:

RULE:[1:$1@$0](.@ACME.ORG)s/@.//
DEFAULT

To also translate the names with a second component, you'd make the rules:

RULE:[1:$1@$0](.@ACME.ORG)s/@.//
RULE:[2:$1@$0](.@ACME.ORG)s/@.//
DEFAULT

If you want to treat all principals from APACHE.ORG with /admin as "admin", your rules would look like:

RULE[2:$1%$2@$0](.%admin@APACHE.ORG)s/./admin/
DEFAULT
    </description>
  </property>
</configuration>